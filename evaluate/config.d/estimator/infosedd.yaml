# @package _global_

defaults:
- _self_
- model: unetmlp

estimator:
  _target_: infosedd.infosedd.InfoSEDD
  args:
    model: ${model}
    ngpus: 1
    mc_estimates: 100
    estimate_entropy: False
    estimate_mutinfo: True
    estimate_oinfo: False
    mc_times: 100
    sampling_eps: 1e-2
    montecarlo: False
    dynkin: True
    use_analytic_score: False
    debug: False
    generate_samples: False
    resume_training: True
    checkpoint_path: null
    is_parametric_marginal: True
    use_marginal_flag: True

    cond: null

    training:
      batch_size: 1024
      accum: 1
      snapshot_freq: 5000
      log_freq: 1
      eval_freq: 5000
      snapshot_freq_for_preemption: 10000
      weight: standard
      snapshot_sampling: True
      ema: 0.999
      checkpoint_dir: "infosedd/checkpoints_ema_mutinfo"
      accelerator: "gpu"
      devices: [7]
      devices: [3]
      max_steps: 100001
      val_check_interval: 5000
      p_marginal: 0.5

    graph:
      type: absorb
      file: data
      report_all: False

    noise:
      type: geometric
      sigma_min: 1e-5
      sigma_max: 10

    sampling:
      predictor: euler
      steps: 128
      noise_removal: True
      eps: 1e-5

    eval:
      batch_size: 1024
      perplexity: True
      perplexity_batch_size: 32

    optim:
      weight_decay: 0
      optimizer: AdamW
      lr: 1e-2
      beta1: 0.9
      beta2: 0.999
      eps: 1e-8
      warmup: 1_000
      gradient_clip_val: 1.0
